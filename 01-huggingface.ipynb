{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Intro\n",
    "\n",
    "Let's use an existing Prodigy dataset in our local Prodigy database and train it on Hugging Face `transformers` step by step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': \"Don't tell that to Anthony Bourdain.\",\n",
       " 'meta': {'source': 'homework2-DSBA6188-UNCC'},\n",
       " '_input_hash': -1138854585,\n",
       " '_task_hash': -1083063769,\n",
       " 'options': [{'id': 'RELEVANT', 'text': 'RELEVANT'},\n",
       "  {'id': 'NOT_RELEVANT', 'text': 'NOT_RELEVANT'}],\n",
       " '_view_id': 'choice',\n",
       " 'config': {'choice_style': 'single'},\n",
       " 'accept': ['NOT_RELEVANT'],\n",
       " 'answer': 'accept',\n",
       " '_timestamp': 1708026240,\n",
       " '_annotator_id': 'hmwk2-eval-ryan',\n",
       " '_session_id': 'hmwk2-eval-ryan',\n",
       " 'sessions': ['hmwk2-eval-chang', 'hmwk2-eval-ryan'],\n",
       " 'versions': [{'text': \"Don't tell that to Anthony Bourdain.\",\n",
       "   'meta': {'source': 'homework2-DSBA6188-UNCC'},\n",
       "   '_input_hash': -1138854585,\n",
       "   '_task_hash': -1083063769,\n",
       "   'options': [{'id': 'RELEVANT', 'text': 'RELEVANT'},\n",
       "    {'id': 'NOT_RELEVANT', 'text': 'NOT_RELEVANT'}],\n",
       "   '_view_id': 'choice',\n",
       "   'config': {'choice_style': 'single'},\n",
       "   'accept': ['NOT_RELEVANT'],\n",
       "   'answer': 'accept',\n",
       "   '_timestamp': 1708026240,\n",
       "   '_annotator_id': 'hmwk2-eval-ryan',\n",
       "   '_session_id': 'hmwk2-eval-ryan',\n",
       "   'sessions': ['hmwk2-eval-chang', 'hmwk2-eval-ryan'],\n",
       "   'default': True}],\n",
       " 'view_id': 'choice'}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from prodigy_hf.textcat import produce_train_eval_datasets,into_hf_format\n",
    "\n",
    "data = \"hmwk2-train,eval:hmwk2-eval-review\"\n",
    "\n",
    "train_examples, valid_examples, variant = produce_train_eval_datasets(data)\n",
    "\n",
    "valid_examples[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training examples have 500 examples\n",
      "Validation examples have 200 examples\n"
     ]
    }
   ],
   "source": [
    "print(f\"Training examples have {len(train_examples)} examples\")\n",
    "print(f\"Validation examples have {len(valid_examples)} examples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training examples in the file were 500 and 500 examples were converted to HF format.\n",
      "Validation examples in the file were 200 and 200 examples were converted to HF format.\n",
      "{0: 'NOT_RELEVANT', 1: 'RELEVANT'}\n",
      "{'NOT_RELEVANT': 0, 'RELEVANT': 1}\n"
     ]
    }
   ],
   "source": [
    "from typing import Dict, Iterable, List, Literal, Optional\n",
    "\n",
    "def get_label_names(examples: List[Dict], variant: Literal[\"binary\", \"multi\"]) -> List[str]:\n",
    "    \"\"\"We have to assume exclusive textcat here. So the first example contains all labels.\"\"\"\n",
    "    if variant == \"multi\":\n",
    "        return [ex['id'] for ex in examples[0]['options']]\n",
    "    return [\"accept\", \"reject\"]\n",
    "\n",
    "def into_hf_format2(train_examples: List[Dict], valid_examples: List[Dict], variant: Literal[\"binary\", \"multi\"]):\n",
    "    \"\"\"Turn the examples into variables/format that Huggingface expects.\"\"\"\n",
    "    label_names = get_label_names(train_examples, variant)\n",
    "    id2label = {i: n for i, n in enumerate(label_names)}\n",
    "    label2id = {n: i for i, n in enumerate(label_names)}\n",
    "\n",
    "    def generator(examples) -> Iterable[Dict]:\n",
    "        for ex in examples:\n",
    "            label = None\n",
    "            if variant == \"binary\":\n",
    "                label = label2id[ex[\"answer\"]]\n",
    "            if (variant == \"multi\") and ex['accept']:\n",
    "                # It could be that the dataset was accepted but didn't have anything selected. \n",
    "                label = label2id[ex[\"accept\"][0]]\n",
    "            if label is not None: \n",
    "                yield {\n",
    "                    \"text\": ex[\"text\"],\n",
    "                    \"label\": label\n",
    "                }\n",
    "\n",
    "    train_out = list(generator(train_examples))\n",
    "    valid_out = list(generator(valid_examples))\n",
    "    return train_out, valid_out, label_names, id2label, label2id\n",
    "\n",
    "gen_train, gen_valid, label_list, id2lab, lab2id = into_hf_format2(train_examples, valid_examples, variant)\n",
    "print(f\"Training examples in the file were {len(train_examples)} and {len(gen_train)} examples were converted to HF format.\")\n",
    "print(f\"Validation examples in the file were {len(valid_examples)} and {len(gen_valid)} examples were converted to HF format.\")\n",
    "print(id2lab)\n",
    "print(lab2id)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': \"A ss pan isn't going to hold it's heat as well as cast iron. If you want the best browning, it's gotta be cast iron. If you're making a pan sauce aftward, then ss is a good choice.\",\n",
       " 'label': 1}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert to Prodigy dataset\n",
    "from datasets import Dataset, DatasetDict\n",
    "\n",
    "prodigy_dataset = DatasetDict(\n",
    "        train=Dataset.from_list(gen_train),\n",
    "        eval=Dataset.from_list(gen_valid)\n",
    "    )\n",
    "\n",
    "prodigy_dataset['train'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 500/500 [00:00<00:00, 8508.61 examples/s]\n",
      "Map: 100%|██████████| 200/200 [00:00<00:00, 8617.05 examples/s]\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, DataCollatorWithPadding\n",
    "\n",
    "model_name = \"distilbert-base-uncased\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "def preprocess_function(examples):\n",
    "    return tokenizer(examples[\"text\"], truncation=True, padding=True)\n",
    "\n",
    "tokenized_dataset = prodigy_dataset.map(preprocess_function, batched=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Data collators](https://huggingface.co/docs/transformers/v4.37.2/en/main_classes/data_collator#data-collator) are objects that will form a batch by using a list of dataset elements as input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataCollatorWithPadding(tokenizer=DistilBertTokenizerFast(name_or_path='distilbert-base-uncased', vocab_size=30522, model_max_length=512, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'unk_token': '[UNK]', 'sep_token': '[SEP]', 'pad_token': '[PAD]', 'cls_token': '[CLS]', 'mask_token': '[MASK]'}, clean_up_tokenization_spaces=True),  added_tokens_decoder={\n",
       "\t0: AddedToken(\"[PAD]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t100: AddedToken(\"[UNK]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t101: AddedToken(\"[CLS]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t102: AddedToken(\"[SEP]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t103: AddedToken(\"[MASK]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "}, padding=True, max_length=None, pad_to_multiple_of=None, return_tensors='pt')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
    "\n",
    "data_collator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Downloading builder script: 100%|██████████| 4.20k/4.20k [00:00<00:00, 17.4MB/s]\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForSequenceClassification, TrainingArguments, Trainer\n",
    "from prodigy_hf.textcat import build_metrics_func\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    model_name, num_labels=len(id2lab), id2label=id2lab, label2id=lab2id\n",
    ")\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./output/experiment-5/\", # output directory\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    num_train_epochs=5,\n",
    "    weight_decay=0.01,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    "    push_to_hub=False,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_dataset[\"train\"],\n",
    "    eval_dataset=tokenized_dataset[\"eval\"],\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=build_metrics_func(label_list),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RECIPE: Starting training.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/160 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                \n",
      " 20%|██        | 32/160 [01:49<05:29,  2.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.8563199043273926, 'eval_accuracy': 0.315, 'eval_runtime': 11.7239, 'eval_samples_per_second': 17.059, 'eval_steps_per_second': 1.109, 'epoch': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                \n",
      " 40%|████      | 64/160 [03:39<03:41,  2.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.9309298992156982, 'eval_accuracy': 0.59, 'eval_runtime': 11.9687, 'eval_samples_per_second': 16.71, 'eval_steps_per_second': 1.086, 'epoch': 2.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                \n",
      " 60%|██████    | 96/160 [05:32<02:34,  2.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.1233174800872803, 'eval_accuracy': 0.615, 'eval_runtime': 11.8562, 'eval_samples_per_second': 16.869, 'eval_steps_per_second': 1.096, 'epoch': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \n",
      " 80%|████████  | 128/160 [07:24<01:18,  2.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.0534493923187256, 'eval_accuracy': 0.625, 'eval_runtime': 11.9322, 'eval_samples_per_second': 16.761, 'eval_steps_per_second': 1.089, 'epoch': 4.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \n",
      "100%|██████████| 160/160 [09:19<00:00,  2.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.0957821607589722, 'eval_accuracy': 0.62, 'eval_runtime': 11.7455, 'eval_samples_per_second': 17.028, 'eval_steps_per_second': 1.107, 'epoch': 5.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 160/160 [09:23<00:00,  3.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_runtime': 563.3242, 'train_samples_per_second': 4.438, 'train_steps_per_second': 0.284, 'train_loss': 0.353403377532959, 'epoch': 5.0}\n",
      "RECIPE: Total training time: 564s.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "print(\"RECIPE: Starting training.\")\n",
    "tic = time.time()\n",
    "trainer.train()\n",
    "toc = time.time()\n",
    "print(f\"RECIPE: Total training time: {round(toc - tic)}s.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'RELEVANT', 'score': 0.972578227519989},\n",
       " {'label': 'NOT_RELEVANT', 'score': 0.7652834057807922}]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "pipeline = pipeline(\"text-classification\", \"./output/experiment-5/checkpoint-128\")\n",
    "\n",
    "pipeline([\"My recipes includes bananas, apples, and pears.\", \"Basketball is my favorite sport.\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Possible Next Steps\n",
    "\n",
    "1. Upload your datasets to HF datasets (see [Prodigy docs](https://prodi.gy/docs/plugins#hf-hub)); now you can train on Colab with GPU.\n",
    "\n",
    "```\n",
    "# Make sure you're logged in with huggingface-cli login first\n",
    "# change username/reponame to your own HF username and new reponame\n",
    "prodigy hf.upload hmwk2-train,eval:hmwk2-eval-review username/reponame\n",
    "```\n",
    "\n",
    "2. Upload your model to HF Hub\n",
    "\n",
    "```\n",
    "# Push model to the Hub\n",
    "# Make sure you're logged in with huggingface-cli login first\n",
    "trainer.push_to_hub(\"my-awesome-model\")\n",
    "```\n",
    "\n",
    "3. Modify the HF model with a different base model (you'll need to search for possible models)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
